---

title: Philander 2014


keywords: fastai
sidebar: home_sidebar

summary: "Full replication"
description: "Full replication"
nb_path: "35_philander2014.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 35_philander2014.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>INFO:tensorflow:Enabling eager execution
INFO:tensorflow:Enabling v2 tensorshape
INFO:tensorflow:Enabling resource variables
INFO:tensorflow:Enabling tensor equality
INFO:tensorflow:Enabling control flow v2
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This notebook shows how gamba can be used to reproduce findings from Philander's 2014 study on data mining methods for detecting high-risk gamblers.</p>
<ul>
<li><a href="http://www.thetransparencyproject.org/download_index.php">Data Download (thetransparencyproject.org)</a></li>
<li><a href="">Data Description</a></li>
<li><a href="https://www.tandfonline.com/doi/abs/10.1080/14459795.2013.841721">Original Paper</a></li>
</ul>
<p>It uses data available through the transaparency project above, and performs eight distinct supervised machine learning techniques.</p>
<p><strong>Note:</strong> given the high dimensionality of this data (17), the sample size (530) doesn't meet the <a href="https://youtu.be/Dc0sr0kdBVI?t=3414">rule of thumb</a> that 10x17 (or 1700) observations are required for learning to be generalisable. This means that the ouputs of the methods below may change drastically upon repeated executions, and comparison to the original may not be meaningful. That considered, this notebook shows you how to do this kind of analysis using identical methods.</p>
<p>To begin, import gamba as usual;</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">gamba</span> <span class="k">as</span> <span class="nn">gb</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">measures_table</span> <span class="o">=</span> <span class="n">gb</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">prepare_philander_data</span><span class="p">(</span><span class="s1">&#39;AnalyticDataSet_HighRisk.txt&#39;</span><span class="p">,</span> <span class="n">loud</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>530 players loaded
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Logistic-Regressions">Logistic Regressions<a class="anchor-link" href="#Logistic-Regressions"> </a></h2><p>The machine learning module has wrappers for two logistic regression functions which can be used here. As with other machine learning methods in the gamba library, they return both the actual test labels and the predicted labels so that performance metrics can be computed.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include note.html content='throughout this page the naming convention is an abbreviated version of the name for the test labels used, and the same name with a &#8217;p&#8217; on the end to denote the predicted labels.' %}</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include note.html content='you&#8217;ll also notice a train_test_split parameter of 0.696 as a parameter to all of the methods, this is just to make sure that exactly the same train test split happens as in the paper (it defaults to 0.7)' %}</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">log_r</span><span class="p">,</span> <span class="n">log_rp</span> <span class="o">=</span> <span class="n">gb</span><span class="o">.</span><span class="n">machine_learning</span><span class="o">.</span><span class="n">logistic_regression</span><span class="p">(</span><span class="n">measures_table</span><span class="p">,</span> <span class="s1">&#39;self_exclude&#39;</span><span class="p">,</span> <span class="n">train_test_split</span><span class="o">=</span><span class="mf">0.696</span><span class="p">)</span>
<span class="n">lasso_l</span><span class="p">,</span> <span class="n">lasso_lp</span> <span class="o">=</span> <span class="n">gb</span><span class="o">.</span><span class="n">machine_learning</span><span class="o">.</span><span class="n">lasso_logistic_regression</span><span class="p">(</span><span class="n">measures_table</span><span class="p">,</span> <span class="s1">&#39;self_exclude&#39;</span><span class="p">,</span> <span class="n">train_test_split</span><span class="o">=</span><span class="mf">0.696</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Neural-Networks">Neural Networks<a class="anchor-link" href="#Neural-Networks"> </a></h2><p>The following cell uses the <a href="https://keras.io">Keras</a> library to create and train some neural networks as described in the study. The original study uses the R <a href="https://cran.r-project.org/web/packages/nnet/nnet.pdf#Rfn.optim">nnet</a> and <a href="https://cran.r-project.org/web/packages/caret/vignettes/caret.html">caret</a> packages, <a href="https://stackoverflow.com/questions/42417948/how-to-use-size-and-decay-in-nnet">this stackoverflow post</a> was helpful in understanding the original parameters.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Framing the self_exclude label (0 or 1) as a regression problem means creating a neural network which returns a continuous label. The classification version of the neural network used in the original analysis uses an identical network topology but passes two strings as values instead of a 1 or 0. This should in theory have no substantial difference on the performance of the network (given the sample size and identical architectures).</p>
<p>By contrast, the gamba library's neural network methods have subtly different topologies for classification and regression as described in <a href="http://faculty.neu.edu.cn/yury/AAI/Textbook/Deep%20Learning%20with%20Python.pdf">Deep Learning with Python</a>, which are used here.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nn_c</span><span class="p">,</span> <span class="n">nn_cp</span> <span class="o">=</span> <span class="n">gb</span><span class="o">.</span><span class="n">machine_learning</span><span class="o">.</span><span class="n">neural_network_classification</span><span class="p">(</span><span class="n">measures_table</span><span class="p">,</span> <span class="s1">&#39;self_exclude&#39;</span><span class="p">,</span> <span class="n">train_test_split</span><span class="o">=</span><span class="mf">0.696</span><span class="p">)</span>
<span class="n">nn_r</span><span class="p">,</span> <span class="n">nn_rp</span> <span class="o">=</span> <span class="n">gb</span><span class="o">.</span><span class="n">machine_learning</span><span class="o">.</span><span class="n">neural_network_regression</span><span class="p">(</span><span class="n">measures_table</span><span class="p">,</span> <span class="s1">&#39;self_exclude&#39;</span><span class="p">,</span> <span class="n">train_test_split</span><span class="o">=</span><span class="mf">0.696</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Support-Vector-Machines-(SVMs)">Support Vector Machines (SVMs)<a class="anchor-link" href="#Support-Vector-Machines-(SVMs)"> </a></h2><p>The following cell uses <a href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.svm">scikit-learn's SVM</a> methods to create and trains some SVM's. The original paper uses Dimitriadou et al's <a href="https://www.researchgate.net/profile/Friedrich_Leisch/publication/221678005_E1071_Misc_Functions_of_the_Department_of_Statistics_E1071_TU_Wien/links/547305880cf24bc8ea19ad1d/E1071-Misc-Functions-of-the-Department-of-Statistics-E1071-TU-Wien.pdf">implementations in R described here</a>.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">svm_e</span><span class="p">,</span> <span class="n">svm_ep</span> <span class="o">=</span> <span class="n">gb</span><span class="o">.</span><span class="n">machine_learning</span><span class="o">.</span><span class="n">svm_eps_regression</span><span class="p">(</span><span class="n">measures_table</span><span class="p">,</span> <span class="s1">&#39;self_exclude&#39;</span><span class="p">,</span> <span class="n">train_test_split</span><span class="o">=</span><span class="mf">0.696</span><span class="p">)</span>
<span class="n">svm_c</span><span class="p">,</span> <span class="n">svm_cp</span> <span class="o">=</span> <span class="n">gb</span><span class="o">.</span><span class="n">machine_learning</span><span class="o">.</span><span class="n">svm_c_classification</span><span class="p">(</span><span class="n">measures_table</span><span class="p">,</span> <span class="s1">&#39;self_exclude&#39;</span><span class="p">,</span> <span class="n">train_test_split</span><span class="o">=</span><span class="mf">0.696</span><span class="p">)</span>
<span class="n">svm_o</span><span class="p">,</span> <span class="n">svm_op</span> <span class="o">=</span> <span class="n">gb</span><span class="o">.</span><span class="n">machine_learning</span><span class="o">.</span><span class="n">svm_one_classification</span><span class="p">(</span><span class="n">measures_table</span><span class="p">,</span> <span class="s1">&#39;self_exclude&#39;</span><span class="p">,</span> <span class="n">train_test_split</span><span class="o">=</span><span class="mf">0.696</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Random-Forest">Random Forest<a class="anchor-link" href="#Random-Forest"> </a></h2><p>This section implements <a href="https://scikit-learn.org/stable/modules/ensemble.html#forest">scikit-learn's ensemble methods</a> to create random forests for classification and regression</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">rf_r</span><span class="p">,</span> <span class="n">rf_rp</span> <span class="o">=</span> <span class="n">gb</span><span class="o">.</span><span class="n">machine_learning</span><span class="o">.</span><span class="n">rf_regression</span><span class="p">(</span><span class="n">measures_table</span><span class="p">,</span> <span class="s1">&#39;self_exclude&#39;</span><span class="p">,</span> <span class="n">train_test_split</span><span class="o">=</span><span class="mf">0.696</span><span class="p">)</span>
<span class="n">rf_c</span><span class="p">,</span> <span class="n">rf_cp</span> <span class="o">=</span> <span class="n">gb</span><span class="o">.</span><span class="n">machine_learning</span><span class="o">.</span><span class="n">rf_classification</span><span class="p">(</span><span class="n">measures_table</span><span class="p">,</span> <span class="s1">&#39;self_exclude&#39;</span><span class="p">,</span> <span class="n">train_test_split</span><span class="o">=</span><span class="mf">0.696</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="All-Methods-Together">All Methods Together<a class="anchor-link" href="#All-Methods-Together"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally lets present the performance of each of the machine learning techniques using a number of metrics. Not all of the metrics apply to all of the methods, but it's a good way to see roughly how they compare.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">all_results</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">gb</span><span class="o">.</span><span class="n">machine_learning</span><span class="o">.</span><span class="n">compute_performance</span><span class="p">(</span><span class="s1">&#39;Logistic Regression&#39;</span><span class="p">,</span> <span class="n">log_r</span><span class="p">,</span> <span class="n">log_rp</span><span class="p">),</span>
    <span class="n">gb</span><span class="o">.</span><span class="n">machine_learning</span><span class="o">.</span><span class="n">compute_performance</span><span class="p">(</span><span class="s1">&#39;Lasso Logistic Regression&#39;</span><span class="p">,</span> <span class="n">lasso_l</span><span class="p">,</span> <span class="n">lasso_lp</span><span class="p">),</span>
    <span class="n">gb</span><span class="o">.</span><span class="n">machine_learning</span><span class="o">.</span><span class="n">compute_performance</span><span class="p">(</span><span class="s1">&#39;NN Regression&#39;</span><span class="p">,</span> <span class="n">nn_r</span><span class="p">,</span> <span class="n">nn_rp</span><span class="p">),</span>
    <span class="n">gb</span><span class="o">.</span><span class="n">machine_learning</span><span class="o">.</span><span class="n">compute_performance</span><span class="p">(</span><span class="s1">&#39;NN Classification&#39;</span><span class="p">,</span> <span class="n">nn_c</span><span class="p">,</span> <span class="n">nn_cp</span><span class="p">),</span>
    <span class="n">gb</span><span class="o">.</span><span class="n">machine_learning</span><span class="o">.</span><span class="n">compute_performance</span><span class="p">(</span><span class="s1">&#39;SVM eps-Regression&#39;</span><span class="p">,</span> <span class="n">svm_e</span><span class="p">,</span> <span class="n">svm_ep</span><span class="p">),</span>
    <span class="n">gb</span><span class="o">.</span><span class="n">machine_learning</span><span class="o">.</span><span class="n">compute_performance</span><span class="p">(</span><span class="s1">&#39;SVM c-Classification&#39;</span><span class="p">,</span> <span class="n">svm_c</span><span class="p">,</span> <span class="n">svm_cp</span><span class="p">),</span>
    <span class="n">gb</span><span class="o">.</span><span class="n">machine_learning</span><span class="o">.</span><span class="n">compute_performance</span><span class="p">(</span><span class="s1">&#39;SVM one-Classification&#39;</span><span class="p">,</span> <span class="n">svm_o</span><span class="p">,</span> <span class="n">svm_op</span><span class="p">),</span>
    <span class="n">gb</span><span class="o">.</span><span class="n">machine_learning</span><span class="o">.</span><span class="n">compute_performance</span><span class="p">(</span><span class="s1">&#39;RF Regression&#39;</span><span class="p">,</span> <span class="n">rf_r</span><span class="p">,</span> <span class="n">rf_rp</span><span class="p">),</span>
    <span class="n">gb</span><span class="o">.</span><span class="n">machine_learning</span><span class="o">.</span><span class="n">compute_performance</span><span class="p">(</span><span class="s1">&#39;RF Classification&#39;</span><span class="p">,</span> <span class="n">rf_c</span><span class="p">,</span> <span class="n">rf_cp</span><span class="p">)</span>
<span class="p">]</span>

<span class="n">all_results_df</span> <span class="o">=</span> <span class="n">gb</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">all_results</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">all_results_df</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sensitivity</th>
      <th>specificity</th>
      <th>accuracy</th>
      <th>precision</th>
      <th>auc</th>
      <th>odds_ratio</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Logistic Regression</th>
      <td>0.080</td>
      <td>0.901</td>
      <td>0.646</td>
      <td>0.267</td>
      <td>0.490</td>
      <td>0.791</td>
    </tr>
    <tr>
      <th>Lasso Logistic Regression</th>
      <td>0.094</td>
      <td>0.972</td>
      <td>0.683</td>
      <td>0.625</td>
      <td>0.533</td>
      <td>3.646</td>
    </tr>
    <tr>
      <th>NN Regression</th>
      <td>0.431</td>
      <td>0.545</td>
      <td>0.509</td>
      <td>0.306</td>
      <td>0.488</td>
      <td>0.910</td>
    </tr>
    <tr>
      <th>NN Classification</th>
      <td>0.000</td>
      <td>1.000</td>
      <td>0.640</td>
      <td>NaN</td>
      <td>0.500</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>SVM eps-Regression</th>
      <td>0.020</td>
      <td>0.991</td>
      <td>0.683</td>
      <td>0.500</td>
      <td>0.505</td>
      <td>2.180</td>
    </tr>
    <tr>
      <th>SVM c-Classification</th>
      <td>0.000</td>
      <td>1.000</td>
      <td>0.646</td>
      <td>NaN</td>
      <td>0.500</td>
      <td>0.000</td>
    </tr>
    <tr>
      <th>SVM one-Classification</th>
      <td>0.462</td>
      <td>0.505</td>
      <td>0.491</td>
      <td>0.308</td>
      <td>0.483</td>
      <td>0.873</td>
    </tr>
    <tr>
      <th>RF Regression</th>
      <td>0.373</td>
      <td>0.755</td>
      <td>0.634</td>
      <td>0.413</td>
      <td>0.564</td>
      <td>1.825</td>
    </tr>
    <tr>
      <th>RF Classification</th>
      <td>0.241</td>
      <td>0.869</td>
      <td>0.658</td>
      <td>0.481</td>
      <td>0.555</td>
      <td>2.106</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

