{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics\n",
    "\n",
    "> Run statistical tests on measures tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "With a measures table created, the first obvious step is to compute summary statistics across it, which can be compared to the measures tables from other providers or games, etc. and inform further analyses. The gamba library's statistics module contains methods for running these tests, plus some general descriptive methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd, numpy as np\n",
    "from scipy import stats\n",
    "def descriptive_table(measures_table, loud=False, extended=False):\n",
    "    \"Creates the first table found in LaBrie et al's 2008 paper, which presents descriptive statistics for each of the behavioural measures they calculated.\"\n",
    "    \n",
    "    # first pull all of the data out of the dictionary for more readable use\n",
    "    # later on\n",
    "    measure_names = list(measures_table.columns)[1:]\n",
    "\n",
    "    means = []\n",
    "    stds = []\n",
    "    medians = []\n",
    "    stats.iqrs = []\n",
    "    for measure in measure_names:\n",
    "        means.append(measures_table[measure].mean())\n",
    "        stds.append(measures_table[measure].std())\n",
    "        medians.append(measures_table[measure].median())\n",
    "        stats.iqrs.append(stats.iqr(measures_table[measure].values))\n",
    "\n",
    "    if loud:\n",
    "        print(\"calculating descriptive statistics for LaBrie measures\")\n",
    "\n",
    "    descriptive_df = pd.DataFrame(columns=[\"measure\", \"mean\", \"std\", \"median\"])\n",
    "\n",
    "    descriptive_df[\"measure\"] = measure_names\n",
    "    descriptive_df[\"mean\"] = means\n",
    "    descriptive_df[\"std\"] = stds\n",
    "    descriptive_df[\"median\"] = medians\n",
    "    if extended:\n",
    "        descriptive_df[\"iqr\"] = stats.iqrs\n",
    "\n",
    "    descriptive_df.set_index(\"measure\", inplace=True)\n",
    "    descriptive_df = descriptive_df.rename_axis(None)\n",
    "\n",
    "    return descriptive_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ks_test(measures_table):\n",
    "    \"Performs a one sample Kolmogorov-Smirnov test. This approximately indicates whether or not a collection of calculated behavioural measures are normally distributed.\"\n",
    "\n",
    "    measure_names = list(measures_table.columns)[1:]\n",
    "\n",
    "    scores = []\n",
    "    pvals = []\n",
    "    for measure in measure_names:\n",
    "        result = stats.kstest(measures_table[measure], \"norm\")\n",
    "        scores.append(result[0])\n",
    "        pvals.append(result[1])\n",
    "\n",
    "    ks_table = pd.DataFrame(columns=[\"Measure\", \"K-S Score\", \"p\"])\n",
    "\n",
    "    ks_table[\"Measure\"] = measure_names\n",
    "    ks_table[\"K-S Score\"] = scores\n",
    "    ks_table[\"p\"] = pvals\n",
    "\n",
    "    ks_table.set_index(\"Measure\", inplace=True)\n",
    "    ks_table.rename_axis(None, inplace=True)\n",
    "\n",
    "    return ks_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import math\n",
    "def cohens_d(measures_table, label):\n",
    "    \"Calculates Cohen's d value between the behavioural measures of two groups of players. Groups are distinguished using a label column which is either 1 (in group) or 0 (not in group). For example, the column 'in_top5' may represent whether or not a player is in the top 5 % of players by total amount wagered, and would be 1 or 0 for the top 5 and remaining 95 percent respectively.\"\n",
    "\n",
    "    control_group = measures_table[measures_table[label] == 0]\n",
    "\n",
    "    experimental_group = measures_table[measures_table[label] == 1]\n",
    "\n",
    "    measure_names = list(measures_table.columns)[1:]\n",
    "\n",
    "    # remove the label column (no point doing cohens d on it)\n",
    "    measure_names.remove(label)\n",
    "\n",
    "    d_results = []\n",
    "    # do cohens d for each measure\n",
    "    for measure in measure_names:\n",
    "        control_measure = control_group[measure]\n",
    "        experimental_measure = experimental_group[measure]\n",
    "\n",
    "        control_mean = control_measure.mean()\n",
    "        experimental_mean = experimental_measure.mean()\n",
    "\n",
    "        control_sd = control_measure.std()\n",
    "        experimental_sd = experimental_measure.std()\n",
    "\n",
    "        control_n = len(control_measure)\n",
    "        experimental_n = len(experimental_measure)\n",
    "\n",
    "        top_line = ((control_n - 1) * control_sd ** 2) + (\n",
    "            (experimental_n - 1) * experimental_sd ** 2\n",
    "        )\n",
    "\n",
    "        pooled_sd = math.sqrt(top_line / (control_n + experimental_n - 2))\n",
    "\n",
    "        d = (control_mean - experimental_mean) / pooled_sd\n",
    "\n",
    "        d_results.append(d)\n",
    "\n",
    "    # make a nice dataframe to present the results\n",
    "    d_table = pd.DataFrame(columns=[\"Measure\", \"Cohen's d\"])\n",
    "    d_table[\"Measure\"] = measure_names\n",
    "    d_table[\"Cohen's d\"] = d_results\n",
    "\n",
    "    d_table.set_index(\"Measure\", inplace=True)\n",
    "    d_table.rename_axis(None, inplace=True)\n",
    "\n",
    "    return d_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def spearmans_r(measures_table, loud=False):\n",
    "    \"Calculates the coefficients (nonparametric Spearman's r) between a collection of behavioural measures. The upper-right diagonal of the resulting matrix is discarded (symmetric).\"\n",
    "\n",
    "    measure_names = list(measures_table.columns)[1:]\n",
    "\n",
    "    data = []\n",
    "    for column in measure_names:\n",
    "        data.append(measures_table[column].values)\n",
    "\n",
    "    labels = measure_names\n",
    "\n",
    "    coefs = []\n",
    "    p_values = []\n",
    "    for toprow in data:\n",
    "        for siderow in data:\n",
    "            coef, p = stats.spearmanr(toprow, siderow)\n",
    "            coefs.append(coef)\n",
    "            p_values.append(p)\n",
    "\n",
    "    coefs = np.array(coefs)\n",
    "    # reshape as matrix\n",
    "    coef_as_matrix = coefs.reshape(len(data), len(data))\n",
    "    # cut off top-diagonal elements\n",
    "    coef_as_matrix = np.tril(coef_as_matrix, -1)\n",
    "\n",
    "    p_values = np.array(p_values)\n",
    "    p_as_matrix = np.array(p_values).reshape(len(data), len(data))\n",
    "    p_as_matrix = np.tril(p_as_matrix, -1)\n",
    "\n",
    "    coef_df = pd.DataFrame(coef_as_matrix, columns=labels, index=labels)\n",
    "    p_df = pd.DataFrame(p_as_matrix, columns=labels, index=labels)\n",
    "\n",
    "    # now for string manipulation (get the dataframe in a more readable format)\n",
    "    coef_df.replace(0, \"\", inplace=True)\n",
    "    np.fill_diagonal(coef_df.values, \"-\")\n",
    "\n",
    "    p_values = p_df.values\n",
    "    results_size = len(coef_df.columns)\n",
    "    clean_results = np.empty((results_size, results_size), dtype=object)\n",
    "    for r, row in enumerate(coef_df.values):\n",
    "        for e, element in enumerate(row):\n",
    "            if element == \"-\":\n",
    "                clean_results[r, e] = \"-\"\n",
    "                continue\n",
    "            if element == \"\":\n",
    "                clean_results[r, e] = \"\"\n",
    "                continue\n",
    "\n",
    "            p = float(p_values[r, e])\n",
    "\n",
    "            if p < 0.01:\n",
    "                clean_results[r, e] = str(round(element, 2)) + \"**\"\n",
    "            elif p < 0.05:\n",
    "                clean_results[r, e] = str(round(element, 2)) + \"*\"\n",
    "            else:\n",
    "                clean_results[r, e] = round(element, 2)\n",
    "\n",
    "    correlation_df = pd.DataFrame(\n",
    "        clean_results, columns=coef_df.columns, index=coef_df.index\n",
    "    )\n",
    "\n",
    "    return correlation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def calculate_walker_matrix(measures_tables, labels, measure=\"frequency\", loud=False):\n",
    "    \"Performs a two sample Kolmogorov-Smirnov test between collections of measure from different games.\"\n",
    "\n",
    "    data = []\n",
    "    for measures_table in measures_tables:\n",
    "        data.append(measures_table[measure].values)\n",
    "\n",
    "    coefs = []\n",
    "    p_values = []\n",
    "    if loud:\n",
    "        print(\"num tests:\", len(data) * len(data))\n",
    "    for toprow in data:\n",
    "        for siderow in data:\n",
    "            coef, p = stats.ks_2samp(toprow, siderow)\n",
    "            coefs.append(coef)\n",
    "            p_values.append(p)\n",
    "\n",
    "    coefs = np.array(coefs)\n",
    "    # reshape as matrixEOS\n",
    "    coef_as_matrix = coefs.reshape(len(data), len(data))\n",
    "    # cut off top-diagonal elements\n",
    "    coef_as_matrix = np.tril(coef_as_matrix, -1)\n",
    "\n",
    "    p_values = np.array(p_values)\n",
    "    p_as_matrix = np.array(p_values).reshape(len(data), len(data))\n",
    "    p_as_matrix = np.tril(p_as_matrix, -1)\n",
    "\n",
    "    coef_df = pd.DataFrame(coef_as_matrix, columns=labels, index=labels)\n",
    "    p_df = pd.DataFrame(p_as_matrix, columns=labels, index=labels)\n",
    "\n",
    "    # now for string manipulation to get the dataframe in a more readable format\n",
    "    coef_df.replace(0, \"\", inplace=True)\n",
    "    np.fill_diagonal(coef_df.values, \"-\")\n",
    "\n",
    "    p_values = p_df.values\n",
    "    clean_results = np.empty((len(coef_df.columns), len(coef_df.columns)), dtype=object)\n",
    "    for r, row in enumerate(coef_df.values):\n",
    "        for e, element in enumerate(row):\n",
    "            if element == \"-\":\n",
    "                clean_results[r, e] = \"-\"\n",
    "                continue\n",
    "            if element == \"\":\n",
    "                clean_results[r, e] = \"\"\n",
    "                continue\n",
    "\n",
    "            p = float(p_values[r, e])\n",
    "\n",
    "            if p < 0.01:\n",
    "                clean_results[r, e] = str(round(element, 2)) + \"**\"\n",
    "            elif p < 0.05:\n",
    "                clean_results[r, e] = str(round(element, 2)) + \"*\"\n",
    "            else:\n",
    "                clean_results[r, e] = round(element, 2)\n",
    "\n",
    "    clean_df = pd.DataFrame(clean_results, columns=coef_df.columns, index=coef_df.index)\n",
    "    return clean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeled Measures Table Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The statistics module also contains methods for computing statistics between groups as indicated by a label column in the measures table. {% cite labrie2007assessing %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def label_overlap_table(measures_table, labels):\n",
    "    \"Calculates the number of players under a collection of labels (exclusively), and on each pair of labels (again exclusively) in the list provided. This method can be used to reproduce the final table in LaBrie et al's 2007 paper {% cite labrie2007assessing %}.\"\n",
    "    \n",
    "    first_diagonal_values = []\n",
    "    for label in labels:\n",
    "        other_labels = labels.copy()\n",
    "        other_labels.remove(label)\n",
    "\n",
    "        records_with_label = measures_table[measures_table[label] == 1]\n",
    "\n",
    "        records_with_only_label = records_with_label.copy()\n",
    "        for other_label in other_labels:\n",
    "            records_with_only_label = records_with_only_label[\n",
    "                records_with_only_label[other_label] == 0\n",
    "            ]\n",
    "\n",
    "        percentage = len(records_with_only_label) / len(records_with_label) * 100\n",
    "\n",
    "        table_entry = (\n",
    "            str(len(records_with_only_label)) + \" (\" + str(round(percentage)) + \")\"\n",
    "        )\n",
    "        first_diagonal_values.append(table_entry)\n",
    "\n",
    "    left_side = np.zeros((len(first_diagonal_values), len(first_diagonal_values)))\n",
    "    left_side = (pd.DataFrame(left_side)).applymap(str)\n",
    "\n",
    "    np.fill_diagonal(left_side.values, first_diagonal_values)\n",
    "    left_side.index = labels\n",
    "    left_side.replace(\"0.0\", \"-\", inplace=True)\n",
    "\n",
    "    only = [label + \"_only\" for label in labels]\n",
    "    left_side.columns = only\n",
    "\n",
    "    # end of left side (exclusive labels)\n",
    "\n",
    "    # get pairwise combinations of labels (both indexes and label names)\n",
    "    label_combinations = []\n",
    "    index_combinations = []\n",
    "    for index, label in enumerate(labels[:-1]):\n",
    "        for inner_index, remaining_label in enumerate(labels[index + 1 :]):\n",
    "            label_combinations.append([label, remaining_label])\n",
    "            index_combinations.append(\n",
    "                [\n",
    "                    labels.index(label),\n",
    "                    labels.index(label) + labels.index(remaining_label) - 1,\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    # get number of exclusive labels for each pairwise combination\n",
    "    combination_values = []\n",
    "    percentage_values = []\n",
    "    for index, combination in enumerate(label_combinations):\n",
    "        records_with_first = measures_table[measures_table[combination[0]] == 1]\n",
    "        records_with_both = measures_table[\n",
    "            (measures_table[combination[0]] == 1)\n",
    "            & (measures_table[combination[1]] == 1)\n",
    "        ]\n",
    "\n",
    "        records_with_only_both = records_with_both.copy()\n",
    "        other_labels = labels.copy()\n",
    "        other_labels.remove(combination[0])\n",
    "        other_labels.remove(combination[1])\n",
    "        for other_label in other_labels:\n",
    "            records_with_only_both = records_with_only_both[\n",
    "                records_with_only_both[other_label] == 0\n",
    "            ]\n",
    "\n",
    "        combination_values.append(len(records_with_only_both))\n",
    "        percentage_values.append(\n",
    "            len(records_with_only_both) / len(records_with_first) * 100\n",
    "        )\n",
    "\n",
    "    # create and populate a matrix (to be made into a dataframe) to hold the overlap combination results\n",
    "    combination_matrix = np.zeros((len(label_combinations), len(label_combinations)))\n",
    "    for index, value in enumerate(combination_values):\n",
    "        combination_matrix[\n",
    "            index_combinations[index][0], index_combinations[index][1]\n",
    "        ] = value\n",
    "\n",
    "    # make combination matrix a dataframe and rename columns\n",
    "    combination_df = pd.DataFrame(combination_matrix)\n",
    "    combination_columns = []\n",
    "    for label_combination in label_combinations:\n",
    "        combination_columns.append(\" and \".join(label_combination) + \" only\")\n",
    "\n",
    "    # get the number of records which have all labels (members of all groups)\n",
    "    records_meeting_all_labels = measures_table[\n",
    "        measures_table[labels[0]] == 1\n",
    "    ]  # get those meeting the first label\n",
    "    for label in labels[1:]:\n",
    "        records_meeting_all_labels = records_meeting_all_labels[\n",
    "            records_meeting_all_labels[label] == 1\n",
    "        ]\n",
    "\n",
    "    combination_df = combination_df.applymap(str)\n",
    "    combination_df.replace(\"0.0\", \"-\", inplace=True)\n",
    "\n",
    "    combination_df.columns = combination_columns\n",
    "\n",
    "    # add percentage values to exclusive columns (right side)\n",
    "    for index, label_combination in enumerate(index_combinations):\n",
    "        value = combination_df.iloc[label_combination[0], label_combination[1]]\n",
    "        try:\n",
    "            combination_df.iloc[label_combination[0], label_combination[1]] = (\n",
    "                str(round(float(value)))\n",
    "                + \" (\"\n",
    "                + str(round(percentage_values[index]))\n",
    "                + \")\"\n",
    "            )\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    combination_df.index = labels\n",
    "\n",
    "    combination_df[\"all labels\"] = (\n",
    "        str(round(len(records_meeting_all_labels)))\n",
    "        + \" (\"\n",
    "        + str(\n",
    "            round(\n",
    "                len(records_meeting_all_labels)\n",
    "                / len(measures_table[measures_table[labels[0]] == 1])\n",
    "                * 100\n",
    "            )\n",
    "        )\n",
    "        + \")\"\n",
    "    )\n",
    "\n",
    "    complete_table = pd.concat([left_side, combination_df], axis=1)\n",
    "\n",
    "    return complete_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `statistics` module has some utility methods which may not be directly useful for an analysis but can be used to do simple tasks like join measures tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_tables(t1, t2, same_columns=False):\n",
    "    \"Joins two tables (the second to the right hand side of the first), adding '_2' to column names if same_columns parameter is True.\"\n",
    "    if same_columns:\n",
    "        t2.columns = [name + \"_2\" for name in t2.columns]\n",
    "    combined = pd.concat([t1, t2.reindex(t1.index)], axis=1)\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "#export\n",
    "def color_matrix(matrix, cmap):\n",
    "    \"Creates a shaded matrix based on a color map.\"\n",
    "\n",
    "    results_size = len(correlations.columns)\n",
    "    values = np.empty((results_size, results_size), dtype=object)\n",
    "    for r, row in enumerate(correlations.values):\n",
    "        for e, element in enumerate(row):\n",
    "            if element == \"-\":\n",
    "                values[r, e] = 100\n",
    "                continue\n",
    "            if element == \"\":\n",
    "                values[r, e] = np.nan\n",
    "                continue\n",
    "            if \"*\" in str(element):\n",
    "                value = element.replace(\"*\", \"\")\n",
    "                values[r, e] = float(value) * 100\n",
    "            else:\n",
    "                values[r, e] = element * 100\n",
    "\n",
    "    current_cmap = cm.get_cmap(cmap)\n",
    "    current_cmap.set_bad(color=\"white\")\n",
    "    plt.imshow(np.array(values).astype(np.float), cmap=current_cmap)\n",
    "    plt.yticks(range(len(correlations.columns)), list(correlations.columns))\n",
    "    plt.xticks(range(len(correlations.columns)), list(correlations.columns))\n",
    "    plt.xticks(rotation=90)\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.set_ticks([-100, -80, -60, -40, -20, 0, 20, 40, 60, 80, 100])\n",
    "    cbar.set_ticklabels([-1, -0.8, -0.6, -0.4, -0.2, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "    plt.ylabel(\"test\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{% bibliography --cited %}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
