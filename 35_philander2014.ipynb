{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp philander2014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Philander 2014\n",
    "\n",
    "> Full replication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how gamba can be used to reproduce findings from Philander's 2014 study on data mining methods for detecting high-risk gamblers.\n",
    "\n",
    "- [Data Download (thetransparencyproject.org)](http://www.thetransparencyproject.org/download_index.php)\n",
    "- [Data Description]()\n",
    "- [Original Paper](https://www.tandfonline.com/doi/abs/10.1080/14459795.2013.841721)\n",
    "\n",
    "It uses data available through the transaparency project above, and performs eight distinct supervised machine learning techniques.\n",
    "\n",
    "**Note:** given the high dimensionality of this data (17), the sample size (530) doesn't meet the [rule of thumb](https://youtu.be/Dc0sr0kdBVI?t=3414) that 10x17 (or 1700) observations are required for learning to be generalisable. This means that the ouputs of the methods below may change drastically upon repeated executions, and comparison to the original may not be meaningful.\n",
    "\n",
    "To begin, import gamba as usual;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gamba as gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "530 players loaded\n",
      "train:test\n",
      " 369 : 161 ready\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_id</th>\n",
       "      <th>country</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>total_wagered</th>\n",
       "      <th>num_bets</th>\n",
       "      <th>frequency</th>\n",
       "      <th>duration</th>\n",
       "      <th>bets_per_day</th>\n",
       "      <th>net_loss</th>\n",
       "      <th>intensity</th>\n",
       "      <th>variability</th>\n",
       "      <th>frequency_1m</th>\n",
       "      <th>trajectory</th>\n",
       "      <th>z_intensity</th>\n",
       "      <th>z_variability</th>\n",
       "      <th>z_frequency</th>\n",
       "      <th>z_trajectory</th>\n",
       "      <th>self_exclude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1325917</td>\n",
       "      <td>276</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>93.3400</td>\n",
       "      <td>53</td>\n",
       "      <td>22</td>\n",
       "      <td>419</td>\n",
       "      <td>2.409091</td>\n",
       "      <td>14.9900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.685557</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.230259</td>\n",
       "      <td>-0.622850</td>\n",
       "      <td>-0.243764</td>\n",
       "      <td>-0.239622</td>\n",
       "      <td>-0.218470</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>1366865</td>\n",
       "      <td>792</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>160.7257</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>260</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>105.5627</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>32.369628</td>\n",
       "      <td>3</td>\n",
       "      <td>0.630566</td>\n",
       "      <td>-0.111173</td>\n",
       "      <td>-0.057883</td>\n",
       "      <td>-0.415612</td>\n",
       "      <td>0.980193</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>1363496</td>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1834.5600</td>\n",
       "      <td>196</td>\n",
       "      <td>71</td>\n",
       "      <td>390</td>\n",
       "      <td>2.760563</td>\n",
       "      <td>420.3200</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.972459</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.385017</td>\n",
       "      <td>-0.239092</td>\n",
       "      <td>-0.215983</td>\n",
       "      <td>-0.415612</td>\n",
       "      <td>-0.433965</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     player_id  country  gender  age  total_wagered  num_bets  frequency  \\\n",
       "21     1325917      276       1   53        93.3400        53         22   \n",
       "283    1366865      792       1   24       160.7257        14          5   \n",
       "253    1363496      300       1   29      1834.5600       196         71   \n",
       "\n",
       "     duration  bets_per_day  net_loss  intensity  variability  frequency_1m  \\\n",
       "21        419      2.409091   14.9900   1.000000     3.685557             4   \n",
       "283       260      2.800000  105.5627   3.666667    32.369628             3   \n",
       "253       390      2.760563  420.3200   3.000000     7.972459             3   \n",
       "\n",
       "     trajectory  z_intensity  z_variability  z_frequency  z_trajectory  \\\n",
       "21    -0.230259    -0.622850      -0.243764    -0.239622     -0.218470   \n",
       "283    0.630566    -0.111173      -0.057883    -0.415612      0.980193   \n",
       "253   -0.385017    -0.239092      -0.215983    -0.415612     -0.433965   \n",
       "\n",
       "     self_exclude  \n",
       "21              1  \n",
       "283             1  \n",
       "253             1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "philander_data = gb.data.prepare_philander_data('AnalyticDataSet_HighRisk.txt', loud=True)\n",
    "train_measures, test_measures = gb.measures.split_measures_table(philander_data, frac=.696, loud=True)\n",
    "display(train_measures.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_r = gb.machine_learning.logistic_regression(train_measures, test_measures, 'self_exclude')\n",
    "lasso_l = gb.machine_learning.lasso_logistic_regression(train_measures, test_measures, 'self_exclude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "The following cell uses the [Keras](https://keras.io) library to create and train some neural networks as described in the study. The original study uses the R [nnet](https://cran.r-project.org/web/packages/nnet/nnet.pdf#Rfn.optim) and [caret](https://cran.r-project.org/web/packages/caret/vignettes/caret.html) packages, [this stackoverflow post](https://stackoverflow.com/questions/42417948/how-to-use-size-and-decay-in-nnet) was helpful in understanding the original parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Framing the self_exclude label (0 or 1) as a regression problem means creating a neural network with a single output node and clipping the prediction. The classification version of the neural network used in the original analysis uses an identical network topology but passes two strings as values instead of a 1 or 0. This should in theory have no substantial difference on the performance of the network (given the sample size and identical architectures)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ojs/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>auc</th>\n",
       "      <th>odds_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nn_r</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sensitivity  specificity  accuracy  precision  auc  odds_ratio\n",
       "nn_r          1.0          0.0     0.354      0.354  0.5           0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "# classification = discrete output\n",
    "# regression = continuous output\n",
    "\n",
    "def simple_classification_neural_network(train_measures, test_measures, label):\n",
    "    \n",
    "    train_data = train_measures.drop(['player_id', label], axis=1)\n",
    "    train_labels = train_measures[label]\n",
    "    test_data = test_measures.drop(['player_id',label], axis=1)\n",
    "    test_labels = test_measures[label]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(17, activation = 'relu', input_dim = 17))\n",
    "    model.add(Dense(50, activation = 'relu'))\n",
    "    model.add(Dense(units = 1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer = 'adam', \n",
    "                  loss = 'mean_squared_error',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(train_data, train_labels, \n",
    "                        batch_size = 20, epochs = 100,\n",
    "                        validation_data=(test_data, test_labels),\n",
    "                        verbose=False)\n",
    "\n",
    "    # now make a prediction and clip the values to 0 or 1 as in the original code\n",
    "    raw_prediction = model.predict(test_data)\n",
    "    prediction = [value[0] for value in np.where(raw_prediction >= 0.5, 1, 0)]\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "test_labels = test_measures['self_exclude']\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "\n",
    "#nn_r = shallow_neural_network(train_measures, test_measures, 'self_exclude')\n",
    "nn_c = simple_classification_neural_network(train_measures, test_measures, 'self_exclude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines (SVMs)\n",
    "The following cell uses [scikit-learn's SVM](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.svm) methods to create and trains some SVM's. The original paper uses Dimitriadou et al's [implementations in R described here](https://www.researchgate.net/profile/Friedrich_Leisch/publication/221678005_E1071_Misc_Functions_of_the_Department_of_Statistics_E1071_TU_Wien/links/547305880cf24bc8ea19ad1d/E1071-Misc-Functions-of-the-Department-of-Statistics-E1071-TU-Wien.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_e = gb.machine_learning.svm_eps_regression(train_measures, test_measures, 'self_exclude')\n",
    "svm_c = gb.machine_learning.svm_c_classification(train_measures, test_measures, 'self_exclude')\n",
    "svm_o = gb.machine_learning.svm_one_classification(train_measures, test_measures, 'self_exclude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "This section implements [scikit-learn's ensemble methods](https://scikit-learn.org/stable/modules/ensemble.html#forest) to create random forests for classification and regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_r = gb.machine_learning.rf_regression(train_measures, test_measures, 'self_exclude')\n",
    "rf_c = gb.machine_learning.rf_classification(train_measures, test_measures, 'self_exclude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Methods Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn_r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-fc86f1fc89ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmachine_learning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Logistic Regression'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmachine_learning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Lasso Logistic Regression'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlasso_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmachine_learning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NN Regression'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmachine_learning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Same NN Again'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmachine_learning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SVM eps-Regression'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_e\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn_r' is not defined"
     ]
    }
   ],
   "source": [
    "test_labels = test_measures['self_exclude']\n",
    "all_results = [\n",
    "    gb.machine_learning.compute_performance('Logistic Regression', test_labels, log_r),\n",
    "    gb.machine_learning.compute_performance('Lasso Logistic Regression', test_labels, lasso_l),\n",
    "    gb.machine_learning.compute_performance('NN Regression', test_labels, nn_r),\n",
    "    gb.machine_learning.compute_performance('Same NN Again', test_labels, nn_c),\n",
    "    gb.machine_learning.compute_performance('SVM eps-Regression', test_labels, svm_e),\n",
    "    gb.machine_learning.compute_performance('SVM c-Classification', test_labels, svm_c),\n",
    "    gb.machine_learning.compute_performance('SVM one-Classification', test_labels, svm_o),\n",
    "    gb.machine_learning.compute_performance('RF Regression', test_labels, rf_r),\n",
    "    gb.machine_learning.compute_performance('RF Classification', test_labels, rf_c)\n",
    "]\n",
    "\n",
    "all_results_df = pd.concat(all_results)\n",
    "display(all_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'philander_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9d53728362b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mplot_individual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphilander_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1324368\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'philander_data' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_individual(measures_table, player_id):\n",
    "    \n",
    "    measure_cols = measures_table.columns[1:]\n",
    "    player = measures_table[measures_table['player_id'] == player_id]\n",
    "    \n",
    "    for measure in measure_cols:\n",
    "        plt.figure(figsize=[4,2])\n",
    "        hist = plt.hist(measures_table[measure].values, alpha=0.5)\n",
    "        plt.plot([player[measure].values[0], player[measure].values[0]], [0, hist[0].max()], label=measure, color='black')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "plot_individual(philander_data, 1324368)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
